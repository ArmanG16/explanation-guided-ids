import sys
import glob
import os

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))

sys.path.insert(0, os.path.join(BASE_DIR, "pyIDS"))

data_dir = os.path.join(BASE_DIR, "data/processed/bethdataset")

import pandas as pd
from pyids.algorithms.ids_classifier import mine_CARs
from pyids.algorithms.ids import IDS
from pyids.data_structures.ids_rule import IDSRule

from pyarc.qcba.data_structures import QuantitativeDataFrame
import io
import requests

def Beth_Train(max_rows):
    csv_files = glob.glob(os.path.join(data_dir, "*.csv"))
    print(f"Number of CSV files found: {len(csv_files)}")

    df_list = []
    total_rows = 0
    for file in csv_files:
        temp_df = pd.read_csv(file)
        remaining_rows = max_rows - total_rows
        if remaining_rows <= 0:
            break
        if len(temp_df) > remaining_rows:
            temp_df = temp_df.head(remaining_rows)
        df_list.append(temp_df)
        total_rows += len(temp_df)

    df = pd.concat(df_list, ignore_index=True)
    print(f"Total rows loaded: {len(df)}")

    cars = mine_CARs(df, rule_cutoff=50)
    print("\n--- Learned Decision Rules ---")
    print(f"Mined CARs Count: {len(cars)}\n") # CARS are the rules generated by pyARC that pyIDS will select
    lambda_array = [1, 1, 1, 1, 1, 1, 1]

    df = df.astype(object) # Converting all columns to objects to avoid "NaN" datatype errors
    quant_dataframe = QuantitativeDataFrame(df)

    ids = IDS(algorithm="SLS")
    ids.fit(quant_dataframe=quant_dataframe, class_association_rules=cars, lambda_array=lambda_array)

    print("\n--- Learned Decision Rules ---")
    print(f"Total Rules Selected by IDS: {len(ids.clf.rules)}\n")

    print("\n--- Simplified IDS Rule Summaries ---")

    for i, rule in enumerate(ids.clf.rules, start=1):
        car = rule.car

        antecedent = dict(car.antecedent)
        consequent = car.consequent
        confidence = car.confidence
        support = car.support
        f1 = getattr(rule, "f1", None)

        print(f"Rule {i}:")
        print(f"  IF {antecedent}")
        print(f"  THEN {consequent}")
        print(f"  Support: {support:.3f}, Confidence: {confidence:.3f}", end="")
        if f1 is not None:
            print(f", F1: {f1:.3f}")
        else:
            print()


    acc = ids.score(quant_dataframe) # accuracy is the percentage of the dataset covered by the generated rules
    print("\nAccuracy Score: " + str(acc))

if __name__ == "__main__":
    Beth_Train(10000)